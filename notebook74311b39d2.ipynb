{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae2a7ef",
   "metadata": {
    "id": "-b084yTuq8bB",
    "papermill": {
     "duration": 0.004627,
     "end_time": "2023-11-24T16:39:24.138514",
     "exception": false,
     "start_time": "2023-11-24T16:39:24.133887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 众所周知我要干什么\n",
    " 目前做完了第一步\n",
    "\n",
    " 下载并且解压数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c0d6d5",
   "metadata": {
    "id": "2W0R26m1zdiq",
    "papermill": {
     "duration": 0.003907,
     "end_time": "2023-11-24T16:39:24.146670",
     "exception": false,
     "start_time": "2023-11-24T16:39:24.142763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f014604",
   "metadata": {
    "id": "1fIqac1hshmt",
    "outputId": "fb474792-ddb0-49ab-a202-56349f305e19",
    "papermill": {
     "duration": 0.003753,
     "end_time": "2023-11-24T16:39:24.154515",
     "exception": false,
     "start_time": "2023-11-24T16:39:24.150762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37752e",
   "metadata": {
    "id": "YOXt2YQLucfy",
    "outputId": "f51b5179-6e75-4618-fba6-8efff0d41bf5",
    "papermill": {
     "duration": 0.003639,
     "end_time": "2023-11-24T16:39:24.162099",
     "exception": false,
     "start_time": "2023-11-24T16:39:24.158460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9555f083",
   "metadata": {
    "id": "izsWZe8wq8bD",
    "papermill": {
     "duration": 0.003849,
     "end_time": "2023-11-24T16:39:24.169972",
     "exception": false,
     "start_time": "2023-11-24T16:39:24.166123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 数据读入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29757a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T16:39:24.179761Z",
     "iopub.status.busy": "2023-11-24T16:39:24.179404Z",
     "iopub.status.idle": "2023-11-24T16:39:27.554715Z",
     "shell.execute_reply": "2023-11-24T16:39:27.553736Z"
    },
    "id": "wOP2wsi3q8bD",
    "outputId": "a61664ca-c148-49a7-b74f-85304cfede9a",
    "papermill": {
     "duration": 3.38333,
     "end_time": "2023-11-24T16:39:27.557074",
     "exception": false,
     "start_time": "2023-11-24T16:39:24.173744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ISBI_Loader(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        # 初始化函数，读取所有data_path下的图片‘\n",
    "        print(data_path)\n",
    "        if(data_path == ''):\n",
    "            return \n",
    "        self.data_path = data_path\n",
    "        _tester_watch =  data_path + '/input/*.png'\n",
    "        # self.imgs_path = glob.glob(os.path.join(data_path, 'input/*.png'))\n",
    "        # self.imgs_path = glob.glob(_tester_watch)\n",
    "#         self.imgs_path = os.listdir('/kaggle/working'+'/input')\n",
    "        self.imgs_path = os.listdir(data_path+'/input')\n",
    "        for i in range(len(self.imgs_path)):\n",
    "            self.imgs_path[i] = data_path + '/input/' + self.imgs_path[i]\n",
    "\n",
    "    def augment(self, image, flipCode):\n",
    "        # 使用cv2.flip进行数据增强，filpCode为1水平翻转，0垂直翻转，-1水平+垂直翻转\n",
    "        # 我们是彩色图像，不用管\n",
    "        # flip = cv2.flip(image, flipCode)\n",
    "        return image\n",
    "        # return flip\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 根据index读取图片\n",
    "        image_path = self.imgs_path[index]\n",
    "        # 根据image_path生成label_path\n",
    "        label_path = image_path\n",
    "        tempsplit = label_path.split('/')\n",
    "        tempsplit[len(tempsplit)-2]='output'\n",
    "        label_path = tempsplit[0]\n",
    "        for i in range(len(tempsplit)-1):\n",
    "            label_path=label_path+'/'+tempsplit[i+1]\n",
    "#         label_path = image_path.replace('input', 'output')\n",
    "        # 读取训练图片和标签图片\n",
    "#         print(label_path)\n",
    "        image = cv2.imread(image_path)\n",
    "        label = cv2.imread(label_path)\n",
    "        # 将数据转为单通道的图片\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "        label = label.reshape(1, label.shape[0], label.shape[1])\n",
    "        # 处理标签，将像素值为255的改为1\n",
    "        if label.max() > 1:\n",
    "            label = label / 255\n",
    "        # 随机进行数据增强，为2时不做处理\n",
    "        flipCode = random.choice([-1, 0, 1, 2])\n",
    "        if flipCode != 2:\n",
    "            image = self.augment(image, flipCode)\n",
    "            label = self.augment(label, flipCode)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回训练集大小\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     isbi_dataset = ISBI_Loader(\"/kaggle/working/littletrain\")\n",
    "#     print(\"数据个数：\", len(isbi_dataset))\n",
    "#     train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "#                                                batch_size=32,\n",
    "#                                                shuffle=True)\n",
    "#     for image, label in train_loader:\n",
    "#         print(image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa6e3c",
   "metadata": {
    "id": "_58LhXGgq8bG",
    "papermill": {
     "duration": 0.003841,
     "end_time": "2023-11-24T16:39:27.564999",
     "exception": false,
     "start_time": "2023-11-24T16:39:27.561158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unet模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1fa5d3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T16:39:27.574365Z",
     "iopub.status.busy": "2023-11-24T16:39:27.573753Z",
     "iopub.status.idle": "2023-11-24T16:39:27.588603Z",
     "shell.execute_reply": "2023-11-24T16:39:27.587697Z"
    },
    "id": "skk6aHMGq8bG",
    "papermill": {
     "duration": 0.021523,
     "end_time": "2023-11-24T16:39:27.590533",
     "exception": false,
     "start_time": "2023-11-24T16:39:27.569010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\" Parts of the U-Net model \"\"\"\n",
    "\"\"\"https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_parts.py\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13743366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T16:39:27.599817Z",
     "iopub.status.busy": "2023-11-24T16:39:27.599071Z",
     "iopub.status.idle": "2023-11-24T16:39:27.770858Z",
     "shell.execute_reply": "2023-11-24T16:39:27.769861Z"
    },
    "id": "2HT6VZBiq8bH",
    "outputId": "00e323cc-be0e-4313-93ab-a19db3582d65",
    "papermill": {
     "duration": 0.179695,
     "end_time": "2023-11-24T16:39:27.774196",
     "exception": false,
     "start_time": "2023-11-24T16:39:27.594501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (inc): DoubleConv(\n",
      "    (double_conv): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (down1): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down2): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down3): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (down4): Down(\n",
      "    (maxpool_conv): Sequential(\n",
      "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (1): DoubleConv(\n",
      "        (double_conv): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up1): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up2): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up3): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up4): Up(\n",
      "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
      "    (conv): DoubleConv(\n",
      "      (double_conv): Sequential(\n",
      "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (5): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (outc): OutConv(\n",
      "    (conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
    "\"\"\"Refer https://github.com/milesial/Pytorch-UNet/blob/master/unet/unet_model.py\"\"\"\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from .unet_parts import *\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    net = UNet(n_channels=3, n_classes=1)\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7270e29",
   "metadata": {
    "id": "2qK0zM9Pq8bH",
    "papermill": {
     "duration": 0.004636,
     "end_time": "2023-11-24T16:39:27.784519",
     "exception": false,
     "start_time": "2023-11-24T16:39:27.779883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3376bcbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-24T16:39:27.795810Z",
     "iopub.status.busy": "2023-11-24T16:39:27.795031Z",
     "iopub.status.idle": "2023-11-24T16:41:42.140388Z",
     "shell.execute_reply": "2023-11-24T16:41:42.139303Z"
    },
    "id": "CYnfiP25q8bH",
    "outputId": "06eb05c1-a1fc-4da4-f1c2-cc9f39e7c53e",
    "papermill": {
     "duration": 134.352917,
     "end_time": "2023-11-24T16:41:42.142763",
     "exception": false,
     "start_time": "2023-11-24T16:39:27.789846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/little/littletrain/train\n",
      "/kaggle/input/little/littletrain/test\n",
      "train : Loss/train 0.622371240456899\n",
      "test : Loss/train 0.8811939239501954\n",
      "train : Loss/train 0.5725077271461487\n",
      "test : Loss/train 0.5965171098709107\n",
      "train : Loss/train 0.5662465214729309\n",
      "test : Loss/train 0.5652386307716369\n",
      "train : Loss/train 0.5635722895463308\n",
      "test : Loss/train 0.5605841636657715\n",
      "train : Loss/train 0.5617866416772207\n",
      "test : Loss/train 0.5605167388916016\n",
      "train : Loss/train 0.5620243589083354\n",
      "test : Loss/train 0.5853234052658081\n",
      "train : Loss/train 0.5617138107617696\n",
      "test : Loss/train 0.5604898571968079\n",
      "train : Loss/train 0.5638190388679505\n",
      "test : Loss/train 0.5630278825759888\n",
      "train : Loss/train 0.5622169375419617\n",
      "test : Loss/train 0.5601600408554077\n",
      "train : Loss/train 0.5601984262466431\n",
      "test : Loss/train 0.5596546769142151\n",
      "train : Loss/train 0.5674891968568166\n",
      "test : Loss/train 0.5628050208091736\n",
      "train : Loss/train 0.5638785084088643\n",
      "test : Loss/train 0.5617167830467225\n",
      "train : Loss/train 0.5603975137074788\n",
      "test : Loss/train 0.558982539176941\n",
      "train : Loss/train 0.5591055889924367\n",
      "test : Loss/train 0.5594762206077576\n",
      "train : Loss/train 0.5582972506682078\n",
      "test : Loss/train 0.5587143540382385\n",
      "train : Loss/train 0.5573744952678681\n",
      "test : Loss/train 0.557742178440094\n",
      "train : Loss/train 0.5566515902678172\n",
      "test : Loss/train 0.5590619564056396\n",
      "train : Loss/train 0.5575477242469787\n",
      "test : Loss/train 0.5608098626136779\n",
      "train : Loss/train 0.5563594400882721\n",
      "test : Loss/train 0.5591472625732422\n",
      "train : Loss/train 0.5552189310391744\n",
      "test : Loss/train 0.5609825253486633\n",
      "train : Loss/train 0.5547957062721253\n",
      "test : Loss/train 0.5583765745162964\n",
      "train : Loss/train 0.5538907031218211\n",
      "test : Loss/train 0.5595596671104431\n",
      "train : Loss/train 0.5532142460346222\n",
      "test : Loss/train 0.5635920166969299\n",
      "train : Loss/train 0.5525605579217275\n",
      "test : Loss/train 0.5622515439987182\n",
      "train : Loss/train 0.551751991113027\n",
      "test : Loss/train 0.558337128162384\n",
      "train : Loss/train 0.5505867699782053\n",
      "test : Loss/train 0.5589226365089417\n",
      "train : Loss/train 0.5496815820535024\n",
      "test : Loss/train 0.5565380930900574\n",
      "train : Loss/train 0.5482222596804301\n",
      "test : Loss/train 0.5613603115081787\n",
      "train : Loss/train 0.5493462026119232\n",
      "test : Loss/train 0.5794866561889649\n",
      "train : Loss/train 0.5492496033509572\n",
      "test : Loss/train 0.5562517881393433\n",
      "train : Loss/train 0.5466472685337067\n",
      "test : Loss/train 0.564972186088562\n",
      "train : Loss/train 0.544564288854599\n",
      "test : Loss/train 0.5636700510978698\n",
      "train : Loss/train 0.543835969765981\n",
      "test : Loss/train 0.5611445665359497\n",
      "train : Loss/train 0.5444259683291117\n",
      "test : Loss/train 0.5638895034790039\n",
      "train : Loss/train 0.5420334060986837\n",
      "test : Loss/train 0.5610289573669434\n",
      "train : Loss/train 0.5397460599740346\n",
      "test : Loss/train 0.5616021990776062\n",
      "train : Loss/train 0.5395975271860759\n",
      "test : Loss/train 0.5656705856323242\n",
      "train : Loss/train 0.539104284842809\n",
      "test : Loss/train 0.565457022190094\n",
      "train : Loss/train 0.5378998597462972\n",
      "test : Loss/train 0.5648328065872192\n",
      "train : Loss/train 0.5379150569438934\n",
      "test : Loss/train 0.5630124568939209\n"
     ]
    }
   ],
   "source": [
    "# from model.unet_model import UNet\n",
    "# from utils.dataset import ISBI_Loader\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "filepath = '/kaggle/input/little' #填写当前目录\n",
    "\n",
    "def train_net(net, device, data_path, epochs=40, batch_size=1, lr=0.00001):\n",
    "    # 加载训练集\n",
    "    train_path = data_path +'/train'\n",
    "    test_path = data_path+ '/test'\n",
    "    isbi_train_dataset = ISBI_Loader(train_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_train_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    isbi_test_dataset = ISBI_Loader(test_path)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=isbi_test_dataset,\n",
    "                                               batch_size=batch_size,\n",
    "                                               shuffle=True)\n",
    "    # 定义RMSprop算法\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)\n",
    "    # 定义Loss算法\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # best_loss统计，初始化为正无穷\n",
    "    best_loss = float('inf')\n",
    "    # 训练epochs次\n",
    "    for epoch in range(epochs):\n",
    "        # 训练模式\n",
    "        net.train()\n",
    "        # 按照batch_size开始训练\n",
    "        losss = 0\n",
    "        for image, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # 将数据拷贝到device中\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            # 使用网络参数，输出预测结果\n",
    "            pred = net(image)\n",
    "            # 计算loss\n",
    "            loss  = criterion(pred, label)\n",
    "            losss = losss + loss.item()\n",
    "            \n",
    "            # 更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print('train : Loss/train', losss/len(train_loader))\n",
    "        net.eval()\n",
    "        losss = 0\n",
    "        for image, label in test_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # 将数据拷贝到device中\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            # 使用网络参数，输出预测结果\n",
    "            pred = net(image)\n",
    "            # 计算loss\n",
    "            loss = criterion(pred, label)\n",
    "            losss = losss + loss.item()\n",
    "            # 保存loss值最小的网络参数\n",
    "        print('test : Loss/train',losss/len(test_loader))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(net.state_dict(), 'best_model.pth')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 选择设备，有cuda用cuda，没有就用cpu\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # device = 'cpu'\n",
    "    # 加载网络，图片单通道1，分类为1。\n",
    "    torch.cuda.empty_cache() # 显然我们有cuda\n",
    "    net = UNet(n_channels=1, n_classes=1)\n",
    "    # 将网络拷贝到deivce中\n",
    "    net.to(device=device)\n",
    "    # 指定训练集地址，开始训练\n",
    "    data_path = filepath + '/littletrain'\n",
    "    train_net(net, device, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fe382",
   "metadata": {
    "papermill": {
     "duration": 0.01009,
     "end_time": "2023-11-24T16:41:42.163411",
     "exception": false,
     "start_time": "2023-11-24T16:41:42.153321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 完成训练之后评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e04f69e",
   "metadata": {
    "papermill": {
     "duration": 0.01003,
     "end_time": "2023-11-24T16:41:42.183530",
     "exception": false,
     "start_time": "2023-11-24T16:41:42.173500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4053694,
     "sourceId": 7044823,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30588,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 143.575872,
   "end_time": "2023-11-24T16:41:44.318839",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-24T16:39:20.742967",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
